{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_9_3 venv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as  plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection using Deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sarth\\anaconda3\\envs\\EKYC\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': -2.220446049250313e-16,\n",
       " 'threshold': 0.68,\n",
       " 'model': 'VGG-Face',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 80,\n",
       "   'y': 95,\n",
       "   'w': 220,\n",
       "   'h': 220,\n",
       "   'left_eye': (228, 181),\n",
       "   'right_eye': (151, 180)},\n",
       "  'img2': {'x': 80,\n",
       "   'y': 95,\n",
       "   'w': 220,\n",
       "   'h': 220,\n",
       "   'left_eye': (228, 181),\n",
       "   'right_eye': (151, 180)}},\n",
       " 'time': 2.28}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to the images\n",
    "img_path1 = \"../data/Uploaded_face.png\"\n",
    "img_path2 = \"../data/Uploaded_face.png\"\n",
    "models = [\"VGG-Face\",\"Facenet\",\"OpenFace\"]\n",
    "verification = DeepFace.verify(img1_path=img_path1, img2_path=img_path2,model_name=models[0])\n",
    "verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification['verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x': 80,\n",
       "  'y': 95,\n",
       "  'w': 220,\n",
       "  'h': 220,\n",
       "  'left_eye': (228, 181),\n",
       "  'right_eye': (151, 180)},\n",
       " {'x': 80,\n",
       "  'y': 95,\n",
       "  'w': 220,\n",
       "  'h': 220,\n",
       "  'left_eye': (228, 181),\n",
       "  'right_eye': (151, 180)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face1_boundary = verification['facial_areas']['img1']\n",
    "face2_boundary = verification['facial_areas']['img2']\n",
    "\n",
    "face1_boundary, face2_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using face_recognition library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Dlib`**: Dlib is a C++ library with Python bindings, known for its excellent face detection and shape prediction capabilities. It also includes a pre-trained face recognition model.\n",
    "\n",
    "**`Face_recognition`**: This Python library is built on top of dlib and provides a simple API for face recognition tasks. It offers both face detection and recognition functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "face1 = face_recognition.load_image_file(r\"..\\data\\extracted_face_image.png\")\n",
    "face1 = cv2.cvtColor(face1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "face2 = face_recognition.load_image_file(r\"..\\data\\Uploaded_face.png\")\n",
    "face2 = cv2.cvtColor(face2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#--Converting image into encodings\n",
    "face_encode1 = face_recognition.face_encodings(face1)[0]\n",
    "face_encode2 = face_recognition.face_encodings(face2)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(face_recognition.compare_faces([face_encode1],face_encode2)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EKYC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
